üß† Deep Learning Text Generation Projects
This repository contains a collection of practice deep learning models developed during my Data Science course. These models demonstrate various techniques in Natural Language Processing (NLP) with a focus on text generation and sentiment analysis using deep learning architectures.

üìÅ Contents:
LSTM Model.ipynb
An LSTM-based language model trained on sample text data to generate new coherent sequences. Includes tokenization, sequence creation, model training, and text generation.

Transformer Model.ipynb
A custom Transformer architecture for text generation, showcasing positional encoding, multi-head attention, and feedforward networks. Trained on the same sample dataset as the LSTM model.

Sentiment_Analysis.ipynb
A deep learning-based sentiment analysis model using embeddings and LSTM layers. Trained on IMDb movie reviews to classify reviews as positive or negative.

üöÄ Technologies Used:
Python (TensorFlow / Keras)

Jupyter Notebooks

LSTM and Transformer architectures

NLP preprocessing techniques

Tokenization and sequence modeling
